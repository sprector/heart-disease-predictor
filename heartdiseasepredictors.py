# -*- coding: utf-8 -*-
"""HeartDiseasePredictors.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fnn43bLZcxTbNR-fwocfFXRWynNgP8bR
"""

# Libraries
from google.colab import files
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc
from sklearn.feature_selection import RFECV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier

# Load Data
uploaded = files.upload()
filename = next(iter(uploaded.keys()))
data = pd.read_csv(filename)

# EDA
data.info()

data.head()

data.shape

data.describe()

# Distribution Visualizations
for column in data.columns:
    plt.figure(figsize=(8, 6))

    # Plot histogram for current column
    plt.hist(data[column], bins='auto', color='blue', alpha=0.7, rwidth=0.85)

    # Customize plot labels and title
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.title(f'Histogram of {column}')

    # Show plot
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.show()

# Logistic Regression Model

X = data[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]
y = data['target']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Creating and training the logistic regression model
model = LogisticRegression(random_state=100)

# Setting up RFECV to automatically select the optimal number of features
rfecv = RFECV(estimator=model, cv=kfold)
rfecv.fit(X_train_scaled, y_train)

# Print the optimal number of features selected
print(f"Optimal number of features: {rfecv.n_features_}")

# Print the names of selected features
selected_features = np.array(X.columns)[rfecv.support_]
print(f"Selected features: {selected_features}")

# Selecting the optimal features
X_train_rfecv = rfecv.transform(X_train_scaled)
X_test_rfecv = rfecv.transform(X_test_scaled)

# Evaluate the model using cross-validation with optimal features
cv_scores_rfecv = cross_val_score(model, X_train_rfecv, y_train, cv=kfold, scoring='accuracy')
print(f"Mean cross-validation score (RFECV): {cv_scores_rfecv.mean()}")

# Fit the model on the full training set with optimal features
model.fit(X_train_rfecv, y_train)

# Making predictions on the test set with optimal features
predictions_rfecv = model.predict(X_test_rfecv)

# Print accuracy scores with optimal features
accuracy_rfecv = accuracy_score(y_test, predictions_rfecv)
print("Accuracy on Test Set (RFECV):", accuracy_rfecv)


# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks([0, 1], ['No Disease', 'Disease'])
plt.yticks([0, 1], ['No Disease', 'Disease'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.grid(False)
for i in range(2):
    for j in range(2):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > cm.max() / 2. else "black")
plt.show()

# Calculate ROC curve and AUC for RFECV-selected features
y_prob_rfecv = model.predict_proba(X_test_rfecv)[:, 1]
fpr_rfecv, tpr_rfecv, thresholds_rfecv = roc_curve(y_test, y_prob_rfecv)
roc_auc_rfecv = auc(fpr_rfecv, tpr_rfecv)

# Plot ROC curve with AUC
plt.figure(figsize=(8, 6))
plt.plot(fpr_rfecv, tpr_rfecv, color='darkorange', lw=2, label=f'AUC = {roc_auc_rfecv:.2f}')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (RFECV)')
plt.legend(loc="lower right")
plt.show()

# Define features and target variable
X = data[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]
y = data['target']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Creating the Decision Tree classifier
model = DecisionTreeClassifier(random_state=100, max_depth=3, min_samples_split=10, min_samples_leaf=5)

# Setting up RFECV to automatically select the optimal number of features
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
rfecv = RFECV(estimator=model, cv=kfold)
rfecv.fit(X_train_scaled, y_train)

# Print the optimal number of features selected
print(f"Optimal number of features: {rfecv.n_features_}")

# Print the names of selected features
selected_features = np.array(X.columns)[rfecv.support_]
print(f"Selected features: {selected_features}")

# Selecting the optimal features
X_train_rfecv = rfecv.transform(X_train_scaled)
X_test_rfecv = rfecv.transform(X_test_scaled)

# Evaluate the model using cross-validation with optimal features
cv_scores_rfecv = cross_val_score(model, X_train_rfecv, y_train, cv=kfold, scoring='accuracy')
print(f"Mean cross-validation score (RFECV): {cv_scores_rfecv.mean()}")

# Fit the model on the full training set with optimal features
model.fit(X_train_rfecv, y_train)

# Making predictions on the test set with optimal features
predictions_rfecv = model.predict(X_test_rfecv)

# Print accuracy scores with optimal features
accuracy_rfecv = accuracy_score(y_test, predictions_rfecv)
print("Accuracy on Test Set (RFECV):", accuracy_rfecv)

# Plot confusion matrix
cm = confusion_matrix(y_test, predictions_rfecv)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks([0, 1], ['No Disease', 'Disease'])
plt.yticks([0, 1], ['No Disease', 'Disease'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.grid(False)
for i in range(2):
    for j in range(2):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > cm.max() / 2. else "black")
plt.show()

# Visualize the Decision Tree
plt.figure(figsize=(12, 8))
plot_tree(model, feature_names=selected_features, class_names=['No Disease', 'Disease'], filled=True)
plt.title("Decision Tree Visualization")
plt.show()

# Random Forest Classifier

# Define features and target variable
X = data[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]
y = data['target']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Creating the Random Forest classifier
model = RandomForestClassifier(n_estimators=100, random_state=100, max_depth=3, min_samples_split=10, min_samples_leaf=5)

# Fit the model on the training set
model.fit(X_train_scaled, y_train)

# Evaluate the model using cross-validation
cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='accuracy')
print(f"Mean cross-validation score: {cv_scores.mean()}")

# Making predictions on the test set
predictions = model.predict(X_test_scaled)

# Print accuracy score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy on Test Set:", accuracy)

# Plot confusion matrix
cm = confusion_matrix(y_test, predictions)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks([0, 1], ['No Disease', 'Disease'])
plt.yticks([0, 1], ['No Disease', 'Disease'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.grid(False)
for i in range(2):
    for j in range(2):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > cm.max() / 2. else "black")
plt.show()

# Feature importance plot
plt.figure(figsize=(10, 6))
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]
plt.bar(range(X.shape[1]), importances[indices], align='center')
plt.xticks(range(X.shape[1]), np.array(X.columns)[indices], rotation=90)
plt.title('Feature Importance')
plt.tight_layout()
plt.show()

# Handling outliers
from scipy.stats import zscore

# Define numerical and categorical columns
numfeat = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
catfeat = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'target']

# Calculate Z-scores for numerical columns
z_scores = np.abs(zscore(data[numfeat]))

# Define threshold for outlier detection
threshold = 3

# Find indices of outliers
outlier_indices = np.where(z_scores > threshold)[0]

# Remove outliers from numerical columns
filtered_numerical = data[numfeat].drop(outlier_indices)

# Reindex to align indices properly
filtered_numerical.reset_index(drop=True, inplace=True)

# Concatenate filtered numerical columns with categorical columns
filtered_data = pd.concat([filtered_numerical, data[catfeat].iloc[filtered_numerical.index]], axis=1)

# Display dimensions of filtered data
print("Dimensions of filtered data:")
print(filtered_data.shape)

# Support Vector Machine

# Assuming 'filtered_data' is your DataFrame after filtering outliers
# Define features and target variable
X = filtered_data[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]
y = filtered_data['target']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Creating the SVM classifier
model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)

# Fit the model on the training set
model.fit(X_train_scaled, y_train)

# Evaluate the model using cross-validation
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='accuracy')
print(f"Mean cross-validation score: {cv_scores.mean()}")

# Making predictions on the test set
predictions = model.predict(X_test_scaled)

# Print accuracy score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy on Test Set:", accuracy)

# Plot confusion matrix
cm = confusion_matrix(y_test, predictions)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks([0, 1], ['No Disease', 'Disease'])
plt.yticks([0, 1], ['No Disease', 'Disease'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.grid(False)
for i in range(2):
    for j in range(2):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > cm.max() / 2. else "black")
plt.show()

from sklearn.inspection import permutation_importance

# Compute permutation feature importance
result = permutation_importance(model, X_test_scaled, y_test, n_repeats=30, random_state=42)

# Create a bar plot of feature importances
importance_means = result.importances_mean
importance_std = result.importances_std
indices = np.argsort(importance_means)[::-1]

plt.figure(figsize=(12, 6))
plt.bar(range(X.shape[1]), importance_means[indices], yerr=importance_std[indices], align='center')
plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)
plt.title('Permutation Feature Importance for Non-linear SVM')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.tight_layout()
plt.show()

from sklearn.decomposition import PCA
# Perform PCA to reduce dimensions to 2D
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Train the SVM model on PCA-transformed data
model_pca = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)
model_pca.fit(X_train_pca, y_train)

# Plot decision boundaries
def plot_decision_boundaries(X, y, model, ax=None):
    if ax is None:
        ax = plt.gca()
    h = .02  # step size in the mesh
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)
    ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.coolwarm)
    ax.set_xlim(X[:, 0].min(), X[:, 0].max())
    ax.set_ylim(X[:, 1].min(), X[:, 1].max())
    ax.set_xticks(())
    ax.set_yticks(())

plt.figure(figsize=(10, 6))
plot_decision_boundaries(X_train_pca, y_train, model_pca)
plt.title('SVM Decision Boundaries with PCA-Reduced Data')
plt.show()

# KNN Classifier

from sklearn.feature_selection import SelectKBest, f_classif

# Define features and target variable
X = filtered_data[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]
y = filtered_data['target']

# Splitting the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature selection
selector = SelectKBest(score_func=f_classif, k=10)
X_train_selected = selector.fit_transform(X_train, y_train)
X_test_selected = selector.transform(X_test)

# Get selected feature names
selected_features = X.columns[selector.get_support()]

# Standardizing the features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_selected)
X_test_scaled = scaler.transform(X_test_selected)

# Import KNN classifier
from sklearn.neighbors import KNeighborsClassifier

# Creating the KNN classifier
model = KNeighborsClassifier(n_neighbors=5)

# Fit the model on the training set
model.fit(X_train_scaled, y_train)

# Evaluate the model using cross-validation
from sklearn.model_selection import cross_val_score, KFold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='accuracy')
print(f"Mean cross-validation score: {cv_scores.mean()}")

# Making predictions on the test set
predictions = model.predict(X_test_scaled)

# Print accuracy score
from sklearn.metrics import accuracy_score, confusion_matrix
accuracy = accuracy_score(y_test, predictions)
print("Accuracy on Test Set:", accuracy)
print("Selected features:", selected_features)

# Plot confusion matrix
cm = confusion_matrix(y_test, predictions)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks([0, 1], ['No Disease', 'Disease'])
plt.yticks([0, 1], ['No Disease', 'Disease'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.grid(False)
for i in range(2):
    for j in range(2):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > cm.max() / 2. else "black")
plt.show()


# Visualize feature scores
feature_scores = selector.scores_[selector.get_support()]
plt.figure(figsize=(10, 6))
plt.bar(selected_features, feature_scores)
plt.xlabel('Features')
plt.ylabel('Score')
plt.title('Feature Importance Scores')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Reduce the dimensionality of the scaled training set to 2D
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train_scaled)

# Fit the KNN model on the reduced dataset
model.fit(X_train_pca, y_train)

# Transform the test set using the same PCA object
X_test_pca = pca.transform(X_test_scaled)

# Making predictions on the reduced test set
predictions_pca = model.predict(X_test_pca)

# Visualize the scatter plot
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=predictions_pca, cmap=plt.cm.coolwarm, s=50, alpha=0.8)
plt.colorbar(scatter, label='Predicted Class')
plt.title('Scatter Plot of Test Set Predictions')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()